version: "3.8"

services:
  # ---- Redis (message broker + result backend) ----
  redis:
    image: redis:7-alpine
    container_name: medqa-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    restart: unless-stopped

  # ---- FastAPI backend ----
  backend:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: medqa-backend
    ports:
      - "8000:8000"
    env_file:
      - .env
    environment:
      - REDIS_URL=redis://redis:6379/0
      - DATABASE_URL=sqlite:///./data/medqa.db
      - UPLOAD_DIR=/app/data/uploads
      - OUTPUT_DIR=/app/data/outputs
      - FAISS_INDEX_DIR=/app/data/faiss
      - GPU_DEVICE=${GPU_DEVICE:-auto}
      - EMBEDDING_BATCH_SIZE=${EMBEDDING_BATCH_SIZE:-64}
      - GPU_MEMORY_FRACTION=${GPU_MEMORY_FRACTION:-0.8}
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - backend_data:/app/data
    depends_on:
      redis:
        condition: service_healthy
    # Cross-platform Ollama access: host.docker.internal works on Mac/Windows,
    # extra_hosts adds it on Linux
    extra_hosts:
      - "host.docker.internal:host-gateway"
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request; urllib.request.urlopen('http://localhost:8000/health')"]
      interval: 15s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # ---- Celery worker ----
  celery_worker:
    build:
      context: ./backend
      dockerfile: Dockerfile
    container_name: medqa-celery
    command: celery -A app.celery_app worker --loglevel=info --concurrency=${CELERY_CONCURRENCY:-2}
    env_file:
      - .env
    environment:
      - REDIS_URL=redis://redis:6379/0
      - DATABASE_URL=sqlite:///./data/medqa.db
      - UPLOAD_DIR=/app/data/uploads
      - OUTPUT_DIR=/app/data/outputs
      - FAISS_INDEX_DIR=/app/data/faiss
      - GPU_DEVICE=${GPU_DEVICE:-auto}
      - EMBEDDING_BATCH_SIZE=${EMBEDDING_BATCH_SIZE:-64}
      - GPU_MEMORY_FRACTION=${GPU_MEMORY_FRACTION:-0.8}
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    volumes:
      - backend_data:/app/data
    depends_on:
      redis:
        condition: service_healthy
      backend:
        condition: service_healthy
    extra_hosts:
      - "host.docker.internal:host-gateway"
    restart: unless-stopped
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

  # ---- React frontend ----
  frontend:
    build:
      context: ./frontend
      dockerfile: Dockerfile
    container_name: medqa-frontend
    ports:
      - "3000:3000"
    depends_on:
      backend:
        condition: service_healthy
    restart: unless-stopped

volumes:
  redis_data:
  backend_data:
